{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy==2.0.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: rembg in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (2.0.59)\n",
      "Requirement already satisfied: pymatting in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (1.1.12)\n",
      "Requirement already satisfied: opencv-python in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: ipython in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (8.28.0)\n",
      "Requirement already satisfied: pillow in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (11.0.0)\n",
      "Requirement already satisfied: packaging in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from kagglehub) (4.66.6)\n",
      "Requirement already satisfied: jsonschema in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (4.23.0)\n",
      "Requirement already satisfied: onnxruntime in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (1.19.2)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (4.10.0.84)\n",
      "Requirement already satisfied: pooch in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (1.8.2)\n",
      "Requirement already satisfied: scikit-image in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (0.24.0)\n",
      "Requirement already satisfied: scipy in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from rembg) (1.14.1)\n",
      "Requirement already satisfied: numba!=0.49.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from pymatting) (0.60.0)\n",
      "Requirement already satisfied: decorator in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from numba!=0.49.0->pymatting) (0.43.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from jsonschema->rembg) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from jsonschema->rembg) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from jsonschema->rembg) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from jsonschema->rembg) (0.20.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from onnxruntime->rembg) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from onnxruntime->rembg) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from onnxruntime->rembg) (5.28.3)\n",
      "Requirement already satisfied: sympy in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from onnxruntime->rembg) (1.13.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from pooch->rembg) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from requests->kagglehub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from scikit-image->rembg) (3.4.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from scikit-image->rembg) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from scikit-image->rembg) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from scikit-image->rembg) (0.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from stack-data->ipython) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from stack-data->ipython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from stack-data->ipython) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime->rembg) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages (from sympy->onnxruntime->rembg) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub numpy==2.0.0 rembg pymatting opencv-python ipython pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/upe/Desktop/aura/aura/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jafarhussain786/human-emotionssad-faces?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14.2M/14.2M [00:00<00:00, 20.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jafarhussain786/human-emotionsfear-faces?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86.6M/86.6M [00:04<00:00, 20.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jafarhussain786/human-emotionssuprise-faces?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.91M/8.91M [00:00<00:00, 20.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1',\n",
       " '/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionssad-faces/versions/1',\n",
       " '/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionsangry-faces/versions/1',\n",
       " '/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionsfear-faces/versions/1',\n",
       " '/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionssuprise-faces/versions/1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub # we are using an api to import kagglehub's dataset\n",
    "\n",
    "paths = []\n",
    "paths.append(kagglehub.dataset_download(\"jafarhussain786/human-emotionshappy-faces\"))\n",
    "paths.append(kagglehub.dataset_download(\"jafarhussain786/human-emotionssad-faces\"))\n",
    "paths.append(kagglehub.dataset_download(\"jafarhussain786/human-emotionsangry-faces\"))\n",
    "paths.append(kagglehub.dataset_download(\"jafarhussain786/human-emotionsfear-faces\"))\n",
    "paths.append(kagglehub.dataset_download(\"jafarhussain786/human-emotionssuprise-faces\"))\n",
    "\n",
    "emotions = [\"happy\", \"sad\", \"angry\", \"fear\", \"surprise\"]\n",
    "paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Manipulation\n",
    "\n",
    "Resizing first: Ensures that all subsequent operations work on a consistent image size.\n",
    "Setting the background to black next: Helps to clean up the image before grayscaling, making it more effective.\n",
    "Grayscaling last: Keeps it optional, allowing for flexibility based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import rembg\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "def resize_image(image, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize the image to the target size while maintaining aspect ratio.\n",
    "    Adds padding to ensure the output size is consistent.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    resized_image = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    # Add padding to make it the target size\n",
    "    top = (target_size[0] - new_h) // 2\n",
    "    left = (target_size[1] - new_w) // 2\n",
    "\n",
    "    # Create a black canvas and place the resized image on it\n",
    "    canvas = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    canvas[top:top+new_h, left:left+new_w] = resized_image\n",
    "\n",
    "    return canvas\n",
    "\n",
    "def remove_background(image):\n",
    "    \"\"\"\n",
    "    Remove the background using rembg and return an image with a black background.\n",
    "    \"\"\"\n",
    "    # Convert OpenCV image (BGR) to PIL image (RGB)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = PILImage.fromarray(image_rgb)\n",
    "\n",
    "    # Use rembg to remove the background\n",
    "    image_no_bg = rembg.remove(pil_image)\n",
    "\n",
    "    # Convert back to OpenCV image and replace transparent pixels with black\n",
    "    image_no_bg_cv = np.array(image_no_bg)\n",
    "    image_no_bg_cv = cv2.cvtColor(image_no_bg_cv, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Replace transparent areas with black\n",
    "    if image_no_bg_cv.shape[2] == 4:  # Check if alpha channel exists\n",
    "        alpha_channel = image_no_bg_cv[:, :, 3]\n",
    "        mask = alpha_channel == 0\n",
    "        image_no_bg_cv = image_no_bg_cv[:, :, :3]  # Remove alpha channel\n",
    "        image_no_bg_cv[mask] = [0, 0, 0]  # Set background to black\n",
    "\n",
    "    return image_no_bg_cv\n",
    "\n",
    "def preprocess_image(image, grayscale=True, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess the image by resizing, removing the background, and converting to grayscale.\n",
    "    \"\"\"\n",
    "    # Step 1: Resize the image\n",
    "    image = resize_image(image, target_size)\n",
    "\n",
    "    # Step 2: Remove the background and replace it with black\n",
    "    image = remove_background(image)\n",
    "\n",
    "    # Step 3: Convert to grayscale if specified\n",
    "    if grayscale:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Display and save functions remain the same as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "image_files = []\n",
    "for path in paths:\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_files.append(os.path.join(path, f))\n",
    "\n",
    "DISPLAY_COUNT = len(image_files)\n",
    "image_files = np.array(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionssad-faces/versions/1\n"
     ]
    }
   ],
   "source": [
    "def show_images(path, num_images=1):\n",
    "    print(path)\n",
    "    rand_array = np.random.randint(0, len(image_files), num_images)  # random.ra\n",
    "    for i, image_path in enumerate(image_files[rand_array]):\n",
    "        print(f\"Using image {i+1} for testing: {image_path}\")\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        original_image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        processed_image = preprocess_image(image)\n",
    "\n",
    "        processed_image_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        original_img_pil = PILImage.fromarray(original_image_rgb)\n",
    "        buf_original = io.BytesIO()\n",
    "        original_img_pil.save(buf_original, format='JPEG')\n",
    "        buf_original.seek(0)\n",
    "\n",
    "        processed_img_pil = PILImage.fromarray(processed_image_rgb)\n",
    "        buf_processed = io.BytesIO()\n",
    "        processed_img_pil.save(buf_processed, format='JPEG')\n",
    "        buf_processed.seek(0)\n",
    "\n",
    "        # print(f\"Original Image {i+1}:\")\n",
    "        # display(Image(data=buf_original.getvalue()))\n",
    "\n",
    "        # print(f\"Image {i+1} after ETL:\")\n",
    "        # display(Image(data=buf_processed.getvalue()))\n",
    "\n",
    "show_images(paths[1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/images26.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_1/happy_1_original.jpg\n",
      "Processing image 2: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/images32.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_2/happy_2_original.jpg\n",
      "Processing image 3: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/n-with-happy-face-expression-people-portraits-isolated-in-neutral-bac-W1FJB7.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_3/happy_3_original.jpg\n",
      "Processing image 4: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/image22.jpeg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_4/happy_4_original.jpg\n",
      "Processing image 5: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/500_F_246149573_1dbnEopMZjSflWG4ZvojXhVVV8cTewTW.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_5/happy_5_original.jpg\n",
      "Processing image 6: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/latin-woman-happy-face-beautiful-smile-isolated-neutral-background-154263808.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_6/happy_6_original.jpg\n",
      "Processing image 7: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/images27.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_7/happy_7_original.jpg\n",
      "Processing image 8: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/image18.jpeg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_8/happy_8_original.jpg\n",
      "Processing image 9: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/girl-smiling-happy-face-wallpaper-preview.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_9/happy_9_original.jpg\n",
      "Processing image 10: /Users/upe/.cache/kagglehub/datasets/jafarhussain786/human-emotionshappy-faces/versions/1/images31.jpg\n",
      "Processed image saved to: ./output/emotion_dataset/happy_10/happy_10_original.jpg\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./output/emotion_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_processed_images(path, num_images=1):\n",
    "    for i, image_path in enumerate(image_files[:num_images]):\n",
    "        print(f\"Processing image {i+1}: {image_path}\")\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        processed_image = preprocess_image(image)\n",
    "\n",
    "        processed_image_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        output_file_path = None\n",
    "        for emotion in emotions:\n",
    "            if emotion in image_path:\n",
    "                image_folder = os.path.join(output_dir, f\"{emotion}_{i+1}\")\n",
    "                os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "                output_file_path = os.path.join(image_folder, f\"{emotion}_{i+1}_original.jpg\")\n",
    "\n",
    "        PILImage.fromarray(processed_image_rgb).save(output_file_path)\n",
    "\n",
    "        print(f\"Processed image saved to: {output_file_path}\")\n",
    "\n",
    "save_processed_images(paths[0], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

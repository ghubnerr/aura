{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606865)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606865)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606869)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606869)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606868)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606868)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606866)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606866)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606867)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606867)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2902.63it/s]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606865)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606865)\u001b[0;0m   warnings.warn(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606865)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606868)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606868)\u001b[0;0m   warnings.warn(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   warnings.warn(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606869)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606869)\u001b[0;0m   warnings.warn(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606866)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606866)\u001b[0;0m   warnings.warn(\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6702.84it/s]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606867)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606867)\u001b[0;0m   warnings.warn(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606868)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606869)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606866)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m /aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   warnings.warn(\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6495.24it/s]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606867)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 5945.15it/s]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6393.76it/s]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6563.86it/s]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6887.20it/s]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 5314.29it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/18/24 17:54:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> VideoSys - INFO: Init Pyramid Attention Broadcast. spatial broadcast: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, spatial   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         range: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, spatial threshold: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span><span style=\"font-weight: bold\">]</span>. temporal broadcast: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, temporal range: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         temporal_threshold: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span><span style=\"font-weight: bold\">]</span>. cross broadcast: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, cross range: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, cross          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         threshold: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span><span style=\"font-weight: bold\">]</span>. mlp broadcast: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/18/24 17:54:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m VideoSys - INFO: Init Pyramid Attention Broadcast. spatial broadcast: \u001b[3;92mTrue\u001b[0m, spatial   \n",
       "\u001b[2;36m                    \u001b[0m         range: \u001b[1;36m2\u001b[0m, spatial threshold: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m800\u001b[0m\u001b[1m]\u001b[0m. temporal broadcast: \u001b[3;92mTrue\u001b[0m, temporal range: \u001b[1;36m3\u001b[0m, \n",
       "\u001b[2;36m                    \u001b[0m         temporal_threshold: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m800\u001b[0m\u001b[1m]\u001b[0m. cross broadcast: \u001b[3;92mTrue\u001b[0m, cross range: \u001b[1;36m6\u001b[0m, cross          \n",
       "\u001b[2;36m                    \u001b[0m         threshold: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m800\u001b[0m\u001b[1m]\u001b[0m. mlp broadcast: \u001b[3;92mTrue\u001b[0m.                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]VideoSysWorkerProcess pid=606867)\u001b[0;0m \u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/18/24 17:54:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> VideoSys - INFO: Init parallel manager with dp_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, cp_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, sp_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/18/24 17:54:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m VideoSys - INFO: Init parallel manager with dp_size: \u001b[1;36m1\u001b[0m, cp_size: \u001b[1;36m1\u001b[0m, sp_size: \u001b[1;36m8\u001b[0m        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.26s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.29s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.27s/it]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m Process VideoSysWorkerProcess:\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m Traceback (most recent call last):\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     self.run()\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/mp_utils.py\", line 195, in _run_worker_process\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     worker = worker_factory()\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/engine.py\", line 71, in _create_pipeline\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     pipeline = pipeline_cls(self.config)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/pipelines/latte/pipeline_latte.py\", line 247, in __init__\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     self.set_eval_and_device(device, text_encoder, vae, transformer)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/pipeline.py\", line 19, in set_eval_and_device\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     modules[i] = modules[i].to(device)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2576, in to\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     return super().to(*args, **kwargs)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1340, in to\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     return self._apply(convert)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   [Previous line repeated 4 more times]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 927, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     param_applied = fn(param)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1326, in convert\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m     return t.to(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606871)\u001b[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 7 has a total capacity of 79.15 GiB of which 125.62 MiB is free. Process 1620965 has 77.64 GiB memory in use. Including non-PyTorch memory, this process has 1.37 GiB memory in use. Of the allocated memory 988.03 MiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m Process VideoSysWorkerProcess:\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m Traceback (most recent call last):\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     self.run()\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/mp_utils.py\", line 195, in _run_worker_process\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     worker = worker_factory()\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/engine.py\", line 71, in _create_pipeline\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     pipeline = pipeline_cls(self.config)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/pipelines/latte/pipeline_latte.py\", line 247, in __init__\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     self.set_eval_and_device(device, text_encoder, vae, transformer)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/videosys/core/pipeline.py\", line 19, in set_eval_and_device\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     modules[i] = modules[i].to(device)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2576, in to\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     return super().to(*args, **kwargs)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1340, in to\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     return self._apply(convert)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     module._apply(fn)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   [Previous line repeated 4 more times]\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 927, in _apply\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     param_applied = fn(param)\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m   File \"/aul/homes/dullo009/miniconda3/envs/aura/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1326, in convert\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m     return t.to(\n",
      "\u001b[1;36m(VideoSysWorkerProcess pid=606870)\u001b[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 6 has a total capacity of 79.15 GiB of which 123.62 MiB is free. Process 1620965 has 77.64 GiB memory in use. Including non-PyTorch memory, this process has 1.37 GiB memory in use. Of the allocated memory 988.03 MiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/18/24 17:54:09] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> VideoSys - ERROR: Worker VideoSysWorkerProcess pid <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">606871</span> died, exit code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/18/24 17:54:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m VideoSys - ERROR: Worker VideoSysWorkerProcess pid \u001b[1;36m606871\u001b[0m died, exit code: \u001b[1;36m1\u001b[0m          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> VideoSys - INFO: Killing local worker processes                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m VideoSys - INFO: Killing local worker processes                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from videosys import LatteConfig, VideoSysEngine\n",
    "import torch\n",
    "\n",
    "config = LatteConfig(\"maxin-cn/Latte-1\", enable_pab=True, num_gpus = 8)\n",
    "engine = VideoSysEngine(config)\n",
    "\n",
    "prompt = \"Sunset over the sea.\"\n",
    "video = engine.generate(prompt).video[0]\n",
    "engine.save_video(video, f\"./outputs/{prompt}.mp4\")\n",
    "\n",
    "video = torch.tensor(video)\n",
    "video_tensor = video.permute(0, 2, 1, 3, 4).to(engine.pipeline._device)  # [batch_size, channels, num_frames, height, width]\n",
    "latents = engine.pipeline.vae.encode(video_tensor).latent_dist.sample() * engine.pipeline.vae.config.scaling_factor\n",
    "latents = latents.permute(0, 2, 1, 3, 4)  # [batch_size, num_frames, latent_channels, height, width]\n",
    "\n",
    "strength = 0.5\n",
    "noise = torch.randn_like(latents)\n",
    "latents = latents * (1 - strength) + noise * strength * engine.pipeline.scheduler.init_noise_sigma\n",
    "\n",
    "new_prompt = \"Sunset over the sea with dolphins.\"\n",
    "new_video = engine.generate(new_prompt, latents=latents).video[0]\n",
    "engine.save_video(new_video, f\"./outputs/{new_prompt}_based_on_previous.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
